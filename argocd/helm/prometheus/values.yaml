# kube-prometheus-stack Helm Values
# Chart: prometheus-community/kube-prometheus-stack
# Repository: https://prometheus-community.github.io/helm-charts
# Version: 80.x
#
# NOTE: This chart uses kube-prometheus-stack key paths, NOT standalone prometheus paths.
# Reference: https://github.com/prometheus-community/helm-charts/tree/main/charts/kube-prometheus-stack

# ─── Prometheus Server ───────────────────────────────────────
prometheus:
  prometheusSpec:
    resources:
      requests:
        cpu: 200m
        memory: 1Gi
      limits:
        cpu: "1"
        memory: 2Gi
    # Force container resources directly (bypasses operator resource handling)
    containers:
      - name: prometheus
        resources:
          requests:
            cpu: 200m
            memory: 1Gi
          limits:
            cpu: "1"
            memory: 2Gi
        startupProbe:
          httpGet:
            path: /-/ready
            port: http-web
            scheme: HTTP
          failureThreshold: 120
          periodSeconds: 15
          timeoutSeconds: 5
    retention: 30d
    walCompression: true
    storageSpec:
      volumeClaimTemplate:
        spec:
          storageClassName: longhorn-homelab
          accessModes: ["ReadWriteOnce"]
          resources:
            requests:
              storage: 50Gi
    nodeSelector:
      kubernetes.io/hostname: homelab
    securityContext:
      runAsNonRoot: true
      runAsUser: 65534
      runAsGroup: 65534
      fsGroup: 65534
    # Pod-level scrape config for annotation-based discovery
    additionalScrapeConfigs:
      - job_name: 'kubernetes-pods'
        kubernetes_sd_configs:
          - role: pod
        relabel_configs:
          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
            action: keep
            regex: true
          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
            action: replace
            target_label: __metrics_path__
            regex: (.+)
          - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
            action: replace
            regex: ([^:]+)(?::\d+)?;(\d+)
            replacement: $1:$2
            target_label: __address__
          - source_labels: [__meta_kubernetes_namespace]
            action: replace
            target_label: namespace
          - source_labels: [__meta_kubernetes_pod_name]
            action: replace
            target_label: pod

  ingress:
    enabled: true
    ingressClassName: traefik
    annotations:
      traefik.ingress.kubernetes.io/router.entrypoints: websecure
      traefik.ingress.kubernetes.io/router.tls: "true"
      traefik.ingress.kubernetes.io/router.middlewares: automation-prometheus-forward-auth@kubernetescrd
    hosts:
      - prometheus.vectorweight.com
    tls:
      - secretName: vectorweight-wildcard-tls
        hosts:
          - prometheus.vectorweight.com

# ─── Alertmanager ────────────────────────────────────────────
alertmanager:
  alertmanagerSpec:
    resources:
      requests:
        cpu: 50m
        memory: 128Mi
      limits:
        cpu: 200m
        memory: 256Mi
    nodeSelector:
      kubernetes.io/hostname: homelab
    storage:
      volumeClaimTemplate:
        spec:
          storageClassName: longhorn-homelab
          accessModes: ["ReadWriteOnce"]
          resources:
            requests:
              storage: 5Gi

# ─── Node Exporter ───────────────────────────────────────────
prometheus-node-exporter:
  resources:
    requests:
      cpu: 50m
      memory: 64Mi
    limits:
      cpu: 200m
      memory: 128Mi

# ─── Kube State Metrics ─────────────────────────────────────
kube-state-metrics:
  resources:
    requests:
      cpu: 50m
      memory: 128Mi
    limits:
      cpu: 200m
      memory: 256Mi
  nodeSelector:
    kubernetes.io/hostname: homelab

# Grafana configuration (kube-prometheus-stack sub-chart)
grafana:
  adminPassword: ChangeMe123

  grafana.ini:
    server:
      root_url: https://grafana.vectorweight.com
    auth.generic_oauth:
      enabled: true
      name: Keycloak
      allow_sign_up: true
      auto_login: true
      client_id: grafana
      client_secret: ${GF_AUTH_GENERIC_OAUTH_CLIENT_SECRET}
      scopes: openid email profile
      auth_url: https://auth.vectorweight.com/realms/vectorweight/protocol/openid-connect/auth
      token_url: https://auth.vectorweight.com/realms/vectorweight/protocol/openid-connect/token
      api_url: https://auth.vectorweight.com/realms/vectorweight/protocol/openid-connect/userinfo
      role_attribute_path: "contains(realm_access.roles[*], 'admin') && 'Admin' || 'Viewer'"
      signout_redirect_url: https://auth.vectorweight.com/realms/vectorweight/protocol/openid-connect/logout?post_logout_redirect_uri=https%3A%2F%2Fgrafana.vectorweight.com%2Flogin
      tls_skip_verify_insecure: false  # Keycloak uses self-signed cert (cert-manager local CA); proper fix: mount CA bundle
      tls_client_ca: /etc/grafana/ca/tls.crt

  # Datasource provisioning
  additionalDataSources:
    # Loki datasource disabled - Loki not deployed, OpenObserve used for logs instead
    # - name: Loki
    #   type: loki
    #   uid: loki
    #   url: http://loki-gateway.monitoring.svc.cluster.local:80
    #   access: proxy
    #   isDefault: false
    #   jsonData:
    #     maxLines: 1000
    #     derivedFields:
    #       - name: TraceID
    #         matcherRegex: "(?:traceID|trace_id|traceId)[=:]\\s*(\\w+)"
    #         url: "$${__value.raw}"
    #         datasourceUid: tempo
    #         urlDisplayLabel: View Trace
    - name: Tempo
      type: tempo
      uid: tempo
      url: http://tempo.monitoring.svc.cluster.local:3100
      access: proxy
      isDefault: false
      jsonData:
        tracesToLogsV2:
          # Use OpenObserve for log correlation instead of Loki
          datasourceUid: openobserve
          filterByTraceID: true
          filterBySpanID: true
        tracesToMetrics:
          datasourceUid: prometheus
        nodeGraph:
          enabled: true
        serviceMap:
          datasourceUid: prometheus
        # lokiSearch removed - Loki not deployed
    - name: OpenObserve
      type: elasticsearch
      uid: openobserve
      url: http://openobserve-openobserve-standalone.monitoring.svc.cluster.local:5080/api/default
      access: proxy
      isDefault: false
      basicAuth: true
      basicAuthUser: kang@vectorweight.com
      secureJsonData:
        basicAuthPassword: banana12
      jsonData:
        esVersion: "7.10.0"
        timeField: "_timestamp"
        logMessageField: "log"
        logLevelField: "level"

  # Dashboard auto-provisioning via sidecar
  sidecar:
    dashboards:
      enabled: true
      label: grafana_dashboard
      labelValue: "1"
      searchNamespace: ALL
      folderAnnotation: grafana_folder
      provider:
        foldersFromFilesStructure: true

  # Ingress for Grafana
  ingress:
    enabled: true
    ingressClassName: traefik
    annotations:
      traefik.ingress.kubernetes.io/router.entrypoints: websecure
      traefik.ingress.kubernetes.io/router.tls: "true"
    hosts:
      - grafana.vectorweight.com
    tls:
      - secretName: vectorweight-wildcard-tls
        hosts:
          - grafana.vectorweight.com

  nodeSelector:
    kubernetes.io/hostname: homelab

  envFromSecret: grafana-oidc-secret
  # Mount CA certificate for TLS validation
  extraSecretMounts:
    - name: ca-cert
      secretName: vectorweight-selfsigned-tls
      defaultMode: 0444
      mountPath: /etc/grafana/ca
      readOnly: true
