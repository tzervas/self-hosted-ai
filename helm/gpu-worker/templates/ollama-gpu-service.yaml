{{- if .Values.ollama.gpu.enabled }}
apiVersion: v1
kind: Service
metadata:
  name: {{ include "self-hosted-ai-gpu-worker.fullname" . }}-ollama-gpu
  labels:
    app.kubernetes.io/name: {{ include "self-hosted-ai-gpu-worker.name" . }}
    app.kubernetes.io/instance: {{ .Release.Name }}
    app.kubernetes.io/version: {{ .Chart.AppVersion | quote }}
    app.kubernetes.io/managed-by: {{ .Release.Service }}
    app.kubernetes.io/component: ollama-gpu
  {{- with .Values.ollama.gpu.service.annotations }}
  annotations:
    {{- toYaml . | nindent 4 }}
  {{- end }}
spec:
  type: {{ .Values.ollama.gpu.service.type }}
  ports:
    - port: {{ .Values.ollama.gpu.service.port }}
      targetPort: http
      protocol: TCP
      name: http
  selector:
    app.kubernetes.io/name: {{ include "self-hosted-ai-gpu-worker.name" . }}
    app.kubernetes.io/instance: {{ .Release.Name }}
    app.kubernetes.io/component: ollama-gpu
{{- end }}