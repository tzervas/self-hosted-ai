services:
  open-webui:
    image: ghcr.io/open-webui/open-webui:v0.7.2
    container_name: open-webui-server
    ports:
      - "${WEBUI_PORT:-3000}:8080"
    volumes:
      - ${DATA_PATH:-/data}/open-webui:/app/backend/data
    environment:
      - OLLAMA_BASE_URLS=http://ollama-cpu:11434;http://${GPU_WORKER_HOST:-192.168.1.99}:${GPU_WORKER_PORT:-11434}
      - WEBUI_SECRET_KEY=${WEBUI_SECRET_KEY}
      - WEBUI_NAME=${WEBUI_NAME:-Self-Hosted AI Server}
      - WEBUI_ADMIN_EMAIL=${WEBUI_ADMIN_EMAIL:-admin@homelab.local}
      - WEBUI_ADMIN_PASSWORD=${WEBUI_ADMIN_PASSWORD:-admin123}
      - ENABLE_AUTH=${ENABLE_AUTH:-false}
      - ENABLE_SIGNUP=${ENABLE_SIGNUP:-true}
      - ENABLE_COMMUNITY_SHARING=${ENABLE_COMMUNITY_SHARING:-false}
      # SearXNG Web Search Integration
      - ENABLE_RAG_WEB_SEARCH=${ENABLE_RAG_WEB_SEARCH:-true}
      - RAG_WEB_SEARCH_ENGINE=${RAG_WEB_SEARCH_ENGINE:-searxng}
      - SEARXNG_QUERY_URL=${SEARXNG_QUERY_URL:-http://searxng:8080/search?q=<query>&format=json}
      # Image Generation (ComfyUI + A1111)
      - ENABLE_IMAGE_GENERATION=${ENABLE_IMAGE_GENERATION:-true}
      - IMAGE_GENERATION_ENGINE=${IMAGE_GENERATION_ENGINE:-auto}
      - COMFYUI_BASE_URL=${COMFYUI_BASE_URL:-http://${GPU_WORKER_HOST:-192.168.1.99}:8188}
      - COMFYUI_WORKFLOW=${COMFYUI_WORKFLOW}
      - AUTOMATIC1111_BASE_URL=${AUTOMATIC1111_BASE_URL:-http://${GPU_WORKER_HOST:-192.168.1.99}:7860}
      # Legacy/Alternative image generation
      - IMAGES_OPENAI_API_KEY=${IMAGES_OPENAI_API_KEY}
      - IMAGES_OPENAI_API_BASE_URL=${IMAGES_OPENAI_API_BASE_URL}
      - ENABLE_CODE_EXECUTION=${ENABLE_CODE_EXECUTION:-true}
      - CODE_EXECUTION_ENGINE=${CODE_EXECUTION_ENGINE:-gvisor}
      - CODE_EXECUTION_API_URL=${CODE_EXECUTION_API_URL:-http://code-executor:8080}
    depends_on:
      - ollama-cpu
      # - code-executor
      - redis
    restart: unless-stopped
    profiles:
      - basic
      - full
      - monitoring

  ollama-cpu:
    image: ollama/ollama:0.13.5
    container_name: ollama-cpu-server
    ports:
      - "${OLLAMA_PORT:-11434}:11434"
    volumes:
      - ${DATA_PATH:-/data}/ollama-cpu:/root/.ollama
    environment:
      - OLLAMA_NUM_PARALLEL=${OLLAMA_CPU_NUM_PARALLEL:-8}
      - OLLAMA_MAX_LOADED_MODELS=${OLLAMA_CPU_MAX_LOADED_MODELS:-4}
      - OLLAMA_KEEP_ALIVE=${OLLAMA_KEEP_ALIVE:-30m}
      - OLLAMA_NUM_THREADS=${OLLAMA_NUM_THREADS:-56}
    restart: unless-stopped
    profiles:
      - basic
      - full
      - monitoring

  # SearXNG - Self-hosted metasearch engine
  searxng:
    image: searxng/searxng:2026.1.11-cf74e1d9e
    container_name: searxng-server
    ports:
      - "${SEARXNG_PORT:-8082}:8080"
    volumes:
      - ../config/searxng:/etc/searxng:rw
    environment:
      - SEARXNG_BASE_URL=http://${SERVER_HOST:-192.168.1.170}:${SEARXNG_PORT:-8082}
      - SEARXNG_SECRET_KEY=${SEARXNG_SECRET_KEY:-change-me-secure-key}
    depends_on:
      - searxng-redis
    cap_drop:
      - ALL
    cap_add:
      - CHOWN
      - SETGID
      - SETUID
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost:8080/healthz"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped
    profiles:
      - basic
      - full
      - monitoring
      - search

  # Document Ingest Service
  ingest-service:
    build:
      context: ../ingest-service
      dockerfile: Dockerfile
    container_name: ingest-service
    ports:
      - "${INGEST_PORT:-8200}:8200"
    volumes:
      - ${DATA_PATH:-/data}/ingest:/data/ingest
      - ${DATA_PATH:-/data}/documents:/data/documents
    environment:
      - OLLAMA_URL=http://ollama-cpu:11434
      - OPENWEBUI_URL=http://open-webui:8080
      - WATCH_DIR=/data/ingest
      - WATCH_DIR_2=/data/documents
    depends_on:
      - ollama-cpu
    restart: unless-stopped
    profiles:
      - full
      - monitoring

  # code-executor:
  #   image: ghcr.io/etienneperot/safe-code-execution:latest
  #   container_name: code-executor-server
  #   ports:
  #     - "${CODE_EXECUTOR_PORT:-8090}:8080"
  #   environment:
  #     - SANDBOX_RUNTIME=${SANDBOX_RUNTIME:-runsc}
  #     - MAX_EXECUTION_TIME=${MAX_EXECUTION_TIME:-60}
  #     - MAX_MEMORY_MB=${MAX_MEMORY_MB:-1024}
  #     - MAX_OUTPUT_SIZE_MB=${MAX_OUTPUT_SIZE_MB:-10}
  #   restart: unless-stopped
  #   profiles:
  #     - basic
  #     - full
  #     - monitoring

  redis:
    image: redis:8.4.0-alpine
    container_name: redis-server
    ports:
      - "${REDIS_PORT:-6379}:6379"
    volumes:
      - ${DATA_PATH:-/data}/redis:/data
    command: redis-server --appendonly yes
    restart: unless-stopped
    profiles:
      - basic
      - full
      - monitoring

  # Monitoring Profile Services
  prometheus:
    image: prom/prometheus:v3.9.1
    container_name: prometheus-server
    ports:
      - "9090:9090"
    volumes:
      - ${DATA_PATH:-/data}/prometheus:/prometheus
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml:ro
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=200h'
      - '--web.enable-lifecycle'
    restart: unless-stopped
    profiles:
      - monitoring

  grafana:
    image: grafana/grafana:12.3.1
    container_name: grafana-server
    ports:
      - "${GRAFANA_PORT:-3002}:3000"
    volumes:
      - ${DATA_PATH:-/data}/grafana:/var/lib/grafana
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_ADMIN_PASSWORD:-admin}
    depends_on:
      - prometheus
    restart: unless-stopped
    profiles:
      - monitoring

  node-exporter:
    image: prom/node-exporter:v1.10.2
    container_name: node-exporter-server
    ports:
      - "9100:9100"
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    command:
      - '--path.procfs=/host/proc'
      - '--path.rootfs=/rootfs'
      - '--path.sysfs=/host/sys'
      - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)'
    restart: unless-stopped
    profiles:
      - monitoring

  # =============================================================================
  # N8N - Workflow Automation
  # =============================================================================
  n8n:
    image: n8nio/n8n:2.3.4
    container_name: n8n-server
    ports:
      - "${N8N_PORT:-5678}:5678"
    volumes:
      - ${DATA_PATH:-/data}/n8n:/home/node/.n8n
    environment:
      - N8N_HOST=${N8N_HOST:-0.0.0.0}
      - N8N_PORT=5678
      - N8N_PROTOCOL=${N8N_PROTOCOL:-http}
      - WEBHOOK_URL=${N8N_WEBHOOK_URL:-http://localhost:5678}
      - GENERIC_TIMEZONE=${TZ:-America/New_York}
      # Security
      - N8N_BASIC_AUTH_ACTIVE=true
      - N8N_BASIC_AUTH_USER=${N8N_USER:-admin}
      - N8N_BASIC_AUTH_PASSWORD=${N8N_PASSWORD:-changeme}
      - N8N_ENCRYPTION_KEY=${N8N_ENCRYPTION_KEY:-}
      # Execution settings
      - EXECUTIONS_PROCESS=main
      - EXECUTIONS_DATA_PRUNE=true
      - EXECUTIONS_DATA_MAX_AGE=168
    user: "1000:1000"
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://127.0.0.1:5678/healthz"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    restart: unless-stopped
    profiles:
      - full
      - automation

  # Redis for SearXNG (separate instance to avoid conflicts)
  searxng-redis:
    image: redis:8.4.0-alpine
    container_name: searxng-redis
    command: redis-server --save 60 1 --loglevel warning
    volumes:
      - ${DATA_PATH:-/data}/searxng-redis:/data
    restart: unless-stopped
    profiles:
      - basic
      - full
      - monitoring
      - search

  # =============================================================================
  # Traefik - Reverse Proxy with TLS
  # =============================================================================
  traefik:
    image: traefik:v3.6.6
    container_name: traefik-server
    ports:
      - "80:80"
      - "443:443"
      - "5679:5679"   # N8N dedicated HTTPS port
      - "8083:8080"   # Dashboard (disable in production)
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - ${DATA_PATH:-/data}/traefik/certs:/certs
      - ${DATA_PATH:-/data}/traefik/config:/config
    command:
      # API and Dashboard
      - "--api.dashboard=true"
      - "--api.insecure=true"  # Remove in production
      # Providers
      - "--providers.docker=true"
      - "--providers.docker.exposedbydefault=false"
      - "--providers.docker.network=self-hosted-ai"
      - "--providers.file.directory=/config"
      - "--providers.file.watch=true"
      # Entrypoints
      - "--entrypoints.web.address=:80"
      - "--entrypoints.websecure.address=:443"
      - "--entrypoints.n8n.address=:5679"
      - "--entrypoints.n8n.http.tls=true"
      # HTTP to HTTPS redirect
      - "--entrypoints.web.http.redirections.entrypoint.to=websecure"
      - "--entrypoints.web.http.redirections.entrypoint.scheme=https"
      # TLS configuration
      - "--entrypoints.websecure.http.tls=true"
      # Logging
      - "--log.level=INFO"
      - "--accesslog=true"
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.dashboard.rule=Host(`traefik.${DOMAIN:-localhost}`)"
      - "traefik.http.routers.dashboard.service=api@internal"
      - "traefik.http.routers.dashboard.entrypoints=websecure"
    restart: unless-stopped
    profiles:
      - secure
      - production

  # =============================================================================
  # LiteLLM - Unified API Gateway
  # =============================================================================
  litellm:
    image: ghcr.io/berriai/litellm:v1.80.11-stable
    container_name: litellm-proxy
    ports:
      - "${LITELLM_PORT:-4000}:4000"
      - "${LITELLM_METRICS_PORT:-9091}:9090"
    environment:
      # Database URL - password special chars must be URL-encoded
      - "DATABASE_URL=postgresql://${POSTGRES_USER:-litellm}:${POSTGRES_PASSWORD:-litellm}@postgres:5432/${POSTGRES_DB:-litellm}"
      - LITELLM_MASTER_KEY=${LITELLM_MASTER_KEY:-sk-litellm-master-key-changeme}
      - OLLAMA_CPU_URL=http://ollama-cpu:11434
      - OLLAMA_GPU_URL=http://${GPU_WORKER_HOST:-192.168.1.99}:${GPU_WORKER_PORT:-11434}
      - REDIS_HOST=redis
      - REDIS_PORT=6379
    volumes:
      - ../config/litellm-config.yml:/app/config.yaml:ro
    command: --config /app/config.yaml --port 4000
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_started
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:4000/health/readiness')"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    restart: unless-stopped
    profiles:
      - full
      - api-gateway

  # =============================================================================
  # PostgreSQL - Database for LiteLLM
  # =============================================================================
  postgres:
    image: postgres:16-alpine
    container_name: postgres-server
    ports:
      - "${POSTGRES_PORT:-5432}:5432"
    environment:
      - POSTGRES_DB=${POSTGRES_DB:-litellm}
      - POSTGRES_USER=${POSTGRES_USER:-litellm}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-litellm}
    volumes:
      - ${DATA_PATH:-/data}/postgres:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-litellm} -d ${POSTGRES_DB:-litellm}"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped
    profiles:
      - full
      - api-gateway

networks:
  default:
    name: self-hosted-ai
    driver: bridge