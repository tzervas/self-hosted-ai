{
  "name": "Ollama Chat Completion",
  "nodes": [
    {
      "parameters": {
        "httpMethod": "POST",
        "path": "chat",
        "responseMode": "responseNode",
        "options": {}
      },
      "id": "webhook-trigger",
      "name": "Webhook",
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 2,
      "position": [250, 300],
      "webhookId": "ollama-chat"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "http://ollama-gpu:11434/api/chat",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ JSON.stringify({ model: $json.body.model || 'qwen2.5-coder:14b', messages: $json.body.messages, stream: false }) }}",
        "options": {
          "timeout": 300000
        }
      },
      "id": "ollama-request",
      "name": "Ollama Chat",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [470, 300]
    },
    {
      "parameters": {
        "respondWith": "json",
        "responseBody": "={{ $json }}",
        "options": {}
      },
      "id": "respond-webhook",
      "name": "Respond to Webhook",
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1.1,
      "position": [690, 300]
    }
  ],
  "connections": {
    "Webhook": {
      "main": [
        [
          {
            "node": "Ollama Chat",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Ollama Chat": {
      "main": [
        [
          {
            "node": "Respond to Webhook",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "active": false,
  "settings": {
    "executionOrder": "v1"
  },
  "versionId": "1",
  "meta": {
    "instanceId": "self-hosted-ai"
  },
  "tags": [
    {
      "name": "ollama"
    },
    {
      "name": "chat"
    }
  ]
}
