# Model Manifest for Self-Hosted AI Stack
# Comprehensive production-ready multi-modal AI setup
# Used by bootstrap.sh to ensure required models are available
# Models are checked against Ollama API before pulling (no re-downloads)
#
# Model Sources:
#   - Ollama: Censored/standard models from Ollama library
#   - HuggingFace: Uncensored models requiring HF_TOKEN authentication
#
# RTX 5080 VRAM Budget: 16GB
#   - Keep loaded models under 14GB for comfortable inference
#   - Larger models will be quantized (Q4/Q5) before deployment

# GPU Worker Models (akula-prime)
# Optimized for RTX 5080 16GB VRAM - Multi-modal capabilities
gpu_worker:
  host: ${GPU_WORKER_HOST:-192.168.1.99}
  port: ${GPU_WORKER_PORT:-11434}
  models:
    # === CODE GENERATION ===
    # Primary coding model - excellent for Rust, Python, Shell, multi-language
    - name: qwen2.5-coder:14b
      size: 8GB
      purpose: coding
      priority: required
      capabilities: [code_generation, code_review, refactoring, debugging]

    # Advanced coding with reasoning - complex problem solving
    - name: deepseek-coder-v2:16b
      size: 8GB
      purpose: coding
      priority: required
      capabilities: [code_generation, architecture, optimization]

    # Specialized code model - alternative for variety
    - name: codellama:13b
      size: 7GB
      purpose: coding
      priority: optional
      capabilities: [code_completion, code_explanation]

    # === REASONING & PROBLEM SOLVING ===
    # Advanced reasoning for research and analysis
    - name: phi4:latest
      size: 8GB
      purpose: reasoning
      priority: required
      capabilities: [logical_reasoning, mathematics, analysis]

    # General reasoning and instruction following
    - name: llama3.1:8b
      size: 4.7GB
      purpose: reasoning
      priority: required
      capabilities: [instruction_following, reasoning, chat]

    # === VISION & MULTI-MODAL ===
    # Vision language model - image understanding and analysis
    - name: llava:13b
      size: 8GB
      purpose: vision
      priority: required
      capabilities: [image_understanding, ocr, visual_reasoning, image_description]

    # Advanced vision model for detailed analysis
    - name: bakllava:latest
      size: 4.7GB
      purpose: vision
      priority: optional
      capabilities: [image_analysis, visual_qa, scene_understanding]

    # === FUNCTION CALLING & TOOL USE ===
    # Function calling specialist
    - name: mistral:7b-instruct-v0.3
      size: 4.1GB
      purpose: function_calling
      priority: required
      capabilities: [function_calling, tool_use, api_integration, json_mode]

    # Advanced tool use with large context
    - name: llama3.1:70b-instruct-q4_0
      size: 40GB
      purpose: function_calling
      priority: optional
      capabilities: [function_calling, tool_use, complex_reasoning, large_context]

# CPU Server Models (homelab)
# Optimized for 120GB RAM - Embeddings, fallback, and specialized tasks
cpu_server:
  host: ${CPU_SERVER_HOST:-192.168.1.170}
  port: ${CPU_SERVER_PORT:-11434}
  models:
    # === GENERAL PURPOSE ===
    # Fast general chat and fallback
    - name: mistral:7b
      size: 4GB
      purpose: chat
      priority: required
      capabilities: [chat, general_qa, summarization]

    # Lightweight fast model for simple tasks
    - name: phi3:latest
      size: 2GB
      purpose: chat
      priority: required
      capabilities: [chat, quick_responses, simple_tasks]

    # Small efficient model for testing
    - name: gemma2:2b
      size: 1.6GB
      purpose: chat
      priority: optional
      capabilities: [chat, fast_inference]

    # === EMBEDDINGS & RAG ===
    # Primary embedding model - semantic search
    - name: nomic-embed-text:latest
      size: 274MB
      purpose: embeddings
      priority: required
      capabilities: [text_embeddings, semantic_search, rag, document_retrieval]

    # Advanced embeddings - better quality
    - name: mxbai-embed-large:latest
      size: 669MB
      purpose: embeddings
      priority: required
      capabilities: [text_embeddings, semantic_search, high_quality]

    # Specialized embeddings for code
    - name: nomic-embed-text:137m-v1.5-q8_0
      size: 137MB
      purpose: embeddings
      priority: optional
      capabilities: [code_embeddings, fast_embeddings]

    # === SPECIALIZED TASKS ===
    # SQL generation and database queries
    - name: sqlcoder:15b
      size: 8.5GB
      purpose: sql
      priority: optional
      capabilities: [sql_generation, database_queries, data_analysis]

    # Document analysis and extraction
    - name: llama3.1:8b-instruct-q8_0
      size: 8.5GB
      purpose: documents
      priority: optional
      capabilities: [document_analysis, information_extraction, summarization]

    # Math and scientific computing
    - name: deepseek-math:7b
      size: 4.1GB
      purpose: mathematics
      priority: optional
      capabilities: [mathematical_reasoning, symbolic_math, problem_solving]

    # Long context processing (128k tokens)
    - name: qwen2.5:7b
      size: 4.7GB
      purpose: long_context
      priority: optional
      capabilities: [long_context, document_processing, analysis]

# =============================================================================
# HuggingFace Models - Uncensored & Specialized
# =============================================================================
# These models require HF_TOKEN authentication for download
# Source: HuggingFace Hub (not Ollama library)
# Storage: /data/models/huggingface on GPU worker

huggingface:
  # Token stored in sealed secret: huggingface-token
  token_secret: huggingface-token
  cache_dir: /data/models/huggingface
  models:
    # === UNCENSORED TEXT GENERATION ===
    # Primary uncensored model - Dolphin (based on Mistral, 32k context)
    - repo_id: cognitivecomputations/dolphin-2.9.3-mistral-7B-32k
      name: dolphin-mistral-7b
      size_gb: 14
      quantization: Q5_K_M  # Optional: reduces to ~4GB
      purpose: uncensored_chat
      priority: required
      capabilities: [uncensored_generation, long_context, instruction_following, creative_writing]
      notes: "Primary uncensored model - downloaded and ready"

    # Wan2.2 for multimodal video generation (text/image to video)
    - repo_id: Wan-AI/Wan-2.2-1.3B
      name: wan-2.2-1.3b
      size_gb: 2.6
      quantization: FP16  # Can quantize to INT8 (1.3GB) if needed
      purpose: text_to_video
      priority: required
      capabilities: [text_to_video, image_to_video, video_generation]
      notes: "Small efficient video model - fits in VRAM alongside other models"

    # Alternative larger uncensored - WizardLM
    - repo_id: cognitivecomputations/WizardLM-2-8x22B-GGUF
      name: wizardlm-2-8x22b
      size_gb: 140
      quantization: Q4_K_M  # Reduces to ~48GB
      purpose: uncensored_chat
      priority: optional
      capabilities: [uncensored_generation, expert_reasoning, creative_writing]
      notes: "Very large model - CPU only, requires significant RAM"

    # === SPEECH-TO-TEXT (STT) ===
    # Whisper Large v3 Turbo - Fast accurate transcription
    - repo_id: openai/whisper-large-v3-turbo
      name: whisper-large-v3-turbo
      size_gb: 1.5
      purpose: speech_to_text
      priority: required
      capabilities: [speech_to_text, transcription, multilingual, timestamp_extraction]
      notes: "Optimized turbo version - 8x faster than large-v3 with same quality"

    # === VOICE GENERATION (TTS) ===
    # XTTS v2 - High quality multilingual text-to-speech
    - repo_id: coqui/XTTS-v2
      name: xtts-v2
      size_gb: 1.8
      purpose: voice_generation
      priority: required
      capabilities: [text_to_speech, voice_cloning, multilingual, emotional_speech]
      notes: "Uncensored TTS - no content filtering on generated speech"

    # Bark - Alternative TTS with more expressive output
    - repo_id: suno/bark
      name: bark
      size_gb: 5
      purpose: voice_generation
      priority: optional
      capabilities: [text_to_speech, music_generation, sound_effects, expressive]
      notes: "Can generate non-speech sounds like laughter, sighing, music"

    # === SOUND EFFECTS (SFX) GENERATION ===
    # AudioLDM 2 - Text-to-audio generation
    - repo_id: cvssp/audioldm2-large
      name: audioldm2-large
      size_gb: 3.5
      purpose: sfx_generation
      priority: required
      capabilities: [text_to_audio, sound_effects, ambient_sounds, music_generation]
      notes: "Generate any audio from text descriptions"

    # AudioGen - Meta's audio generation model
    - repo_id: facebook/audiogen-medium
      name: audiogen-medium
      size_gb: 1.5
      purpose: sfx_generation
      priority: optional
      capabilities: [text_to_audio, sound_effects, environmental_sounds]

    # === MUSIC GENERATION ===
    # Riffusion - Stable Diffusion fine-tuned for music spectrograms
    - repo_id: riffusion/riffusion-model-v1
      name: riffusion-v1
      size_gb: 2.0
      purpose: music_generation
      priority: required
      capabilities: [text_to_music, spectrogram_generation, music_variations]
      notes: "Fast music generation via visual spectrograms - creative results"

    # MusicGen - High quality music generation
    - repo_id: facebook/musicgen-large
      name: musicgen-large
      size_gb: 3.3
      purpose: music_generation
      priority: optional
      capabilities: [text_to_music, melody_continuation, style_transfer]
      notes: "High fidelity music generation - any genre/style"

# =============================================================================
# ComfyUI Models - Image/Video Generation
# =============================================================================
# Downloaded directly to ComfyUI model directories on GPU worker

comfyui:
  base_path: /data/comfyui/models
  models:
    # === VIDEO GENERATION ===
    # WanVideo 2.2 - Improved text/image to video (1.3B params)
    - type: checkpoint
      name: wan_video_2.2_1.3b.safetensors
      url: https://huggingface.co/Wan-AI/WanVideo-2.2-1.3B/resolve/main/wan_video_2.2_1.3b.safetensors
      path: checkpoints/
      size_gb: 2.6
      purpose: video_generation
      priority: required
      capabilities: [text_to_video, image_to_video, high_quality]
      notes: "Latest WanVideo - improved temporal consistency and motion"

    # Stable Video Diffusion - Image to video (high quality)
    - type: checkpoint
      name: svd_xt_1_1.safetensors
      url: https://huggingface.co/stabilityai/stable-video-diffusion-img2vid-xt-1-1/resolve/main/svd_xt_1_1.safetensors
      path: checkpoints/
      size_gb: 4.7
      purpose: video_generation
      priority: required
      capabilities: [image_to_video, motion_control, high_quality]
      notes: "Stable Video Diffusion XT 1.1 - 25 frames, excellent quality"

    # === IMAGE GENERATION ===
    # SDXL Base - Primary image generation
    - type: checkpoint
      name: sd_xl_base_1.0.safetensors
      url: https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/sd_xl_base_1.0.safetensors
      path: checkpoints/
      size_gb: 6.5
      purpose: image_generation
      priority: required

    # FLUX.1 Schnell - Fast high quality generation
    - type: unet
      name: flux1-schnell.safetensors
      url: https://huggingface.co/black-forest-labs/FLUX.1-schnell/resolve/main/flux1-schnell.safetensors
      path: unet/
      size_gb: 23
      purpose: image_generation
      priority: optional
      notes: "Requires offloading for 16GB VRAM"

    # === UPSCALERS ===
    - type: upscale_models
      name: RealESRGAN_x4plus.pth
      url: https://github.com/xinntao/Real-ESRGAN/releases/download/v0.1.0/RealESRGAN_x4plus.pth
      path: upscale_models/
      size_gb: 0.064
      purpose: upscaling
      priority: required

    # === VAE ===
    - type: vae
      name: sdxl_vae.safetensors
      url: https://huggingface.co/stabilityai/sdxl-vae/resolve/main/sdxl_vae.safetensors
      path: vae/
      size_gb: 0.335
      purpose: vae
      priority: required

    # === MOTION MODULES (AnimateDiff) ===
    - type: animatediff
      name: animatediff_lightning_4step.safetensors
      url: https://huggingface.co/ByteDance/AnimateDiff-Lightning/resolve/main/animatediff_lightning_4step_diffusers.safetensors
      path: animatediff/
      size_gb: 1.5
      purpose: animation
      priority: required
      capabilities: [image_animation, fast_inference, motion_generation]
      notes: "4-step AnimateDiff Lightning - very fast animation generation"

    - type: animatediff
      name: animatediff_lightning_8step.safetensors
      url: https://huggingface.co/ByteDance/AnimateDiff-Lightning/resolve/main/animatediff_lightning_8step_diffusers.safetensors
      path: animatediff/
      size_gb: 1.5
      purpose: animation
      priority: optional
      capabilities: [image_animation, high_quality, motion_generation]
      notes: "8-step version - better quality, slightly slower"

    # === CONTROLNET (Multi-Purpose) ===
    # Canny Edge Detection ControlNet
    - type: controlnet
      name: control_v11p_sd15_canny.pth
      url: https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11p_sd15_canny.pth
      path: controlnet/
      size_gb: 1.4
      purpose: controlnet
      priority: optional
      capabilities: [edge_guided_generation, precise_composition]

    # Depth-Aware ControlNet for SDXL
    - type: controlnet
      name: controlnet-depth-sdxl
      url: https://huggingface.co/diffusers/controlnet-depth-sdxl-1.0/resolve/main/diffusion_pytorch_model.safetensors
      path: controlnet/
      size_gb: 2.5
      purpose: controlnet
      priority: optional
      capabilities: [depth_aware_generation, spatial_consistency, 3d_guidance]
      notes: "SDXL-specific depth control for better spatial composition"

    # Tile ControlNet for Seamless Upscaling
    - type: controlnet
      name: control_v11f1e_sd15_tile.pth
      url: https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11f1e_sd15_tile.pth
      path: controlnet/
      size_gb: 1.4
      purpose: controlnet
      priority: optional
      capabilities: [seamless_upscaling, tile_consistency, artifact_reduction]

    - type: controlnet
      name: control_v11f1e_sd15_tile.pth
      url: https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11f1e_sd15_tile.pth
      path: controlnet/
      size_gb: 1.4
      purpose: controlnet
      priority: required
      capabilities: [upscaling, detail_enhancement, video_consistency]
      notes: "Tile ControlNet - essential for video frame consistency"

    - type: controlnet
      name: controlnet_depth_sdxl.safetensors
      url: https://huggingface.co/diffusers/controlnet-depth-sdxl-1.0/resolve/main/diffusion_pytorch_model.safetensors
      path: controlnet/
      size_gb: 2.5
      purpose: controlnet
      priority: optional
      capabilities: [depth_control, 3d_consistency, video_generation]
      notes: "SDXL depth ControlNet for better 3D understanding"
